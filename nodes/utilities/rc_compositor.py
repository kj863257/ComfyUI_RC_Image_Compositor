"""
RC Interactive Compositor - Single-node interactive compositor
Photoshop-like canvas for compositing foreground over background with rotation and mask erasing
"""

import numpy as np
import torch
from PIL import Image, ImageOps
import folder_paths
import json
from server import PromptServer
from aiohttp import web
import base64
from io import BytesIO


def tensor_to_pil(tensor):
    """Convert ComfyUI tensor (BHWC) to PIL Image"""
    if tensor is None:
        return None
    img_np = tensor.squeeze(0).cpu().numpy()
    img_np = np.clip(img_np * 255.0, 0, 255).astype(np.uint8)
    return Image.fromarray(img_np)


def pil_to_tensor(pil_img):
    """Convert PIL Image to ComfyUI tensor (BHWC)"""
    if pil_img is None:
        return None
    img_np = np.array(pil_img).astype(np.float32) / 255.0
    return torch.from_numpy(img_np).unsqueeze(0)


def image_to_base64(pil_img):
    """Convert PIL Image to base64 data URL"""
    if pil_img is None:
        return None
    buffer = BytesIO()
    pil_img.save(buffer, format="PNG")
    img_bytes = buffer.getvalue()
    img_base64 = base64.b64encode(img_bytes).decode('utf-8')
    return f"data:image/png;base64,{img_base64}"


PASS_FORWARD_MESSAGE = "请调整好位置后打开向后传递以继续 / Please enable Pass Forward after adjusting the composition."


def compose_from_transform(background_img, foreground_img, transform, mask_data=None):
    if not transform:
        return None, None

    bg_rgba = background_img.convert("RGBA")
    fg_rgba = foreground_img.convert("RGBA")

    mask_img = None
    if mask_data:
        try:
            if "base64," in mask_data:
                mask_data = mask_data.split("base64,", 1)[1]
            mask_bytes = base64.b64decode(mask_data)
            mask_img = Image.open(BytesIO(mask_bytes)).convert("L")
        except Exception:
            mask_img = None
    if mask_img:
        if mask_img.size != fg_rgba.size:
            mask_img = mask_img.resize(fg_rgba.size, Image.BICUBIC)
        fg_rgba = fg_rgba.copy()
        fg_rgba.putalpha(mask_img)

    def safe_float(value, default):
        try:
            if value is None:
                return default
            return float(value)
        except (TypeError, ValueError):
            return default

    width = safe_float(transform.get("width"), fg_rgba.width)
    height = safe_float(transform.get("height"), fg_rgba.height)

    scale_x = max(safe_float(transform.get("scaleX"), 1.0), 1e-4)
    scale_y = max(safe_float(transform.get("scaleY"), 1.0), 1e-4)
    rotation = safe_float(transform.get("rotation"), 0.0)
    offset_x = safe_float(transform.get("x"), 0.0)
    offset_y = safe_float(transform.get("y"), 0.0)

    scaled_width = max(1, int(round(width * scale_x)))
    scaled_height = max(1, int(round(height * scale_y)))

    scaled_fg = fg_rgba.resize((scaled_width, scaled_height), Image.BICUBIC)
    rotated_fg = scaled_fg.rotate(-rotation, expand=True, resample=Image.BICUBIC)

    center_x = offset_x + (width * scale_x) / 2.0
    center_y = offset_y + (height * scale_y) / 2.0

    paste_x = int(round(center_x - rotated_fg.width / 2.0))
    paste_y = int(round(center_y - rotated_fg.height / 2.0))

    temp_canvas = Image.new("RGBA", bg_rgba.size, (0, 0, 0, 0))
    temp_canvas.paste(rotated_fg, (paste_x, paste_y), rotated_fg)

    composite = Image.alpha_composite(bg_rgba, temp_canvas)

    alpha_channel = rotated_fg.split()[3]
    mask_img = Image.new("L", bg_rgba.size, 0)
    mask_img.paste(alpha_channel, (paste_x, paste_y))

    return composite.convert("RGB"), mask_img


class RC_InteractiveCompositor:
    """
    Interactive compositor node with embedded Fabric.js canvas
    Features: position, scale, rotate foreground, erase foreground mask
    """

    DESCRIPTION = "Interactive Photoshop-like compositor with embedded canvas"
    CATEGORY = "RC/Utilities"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "background": ("IMAGE", {"tooltip": "Background image layer (defines canvas size)"}),
                "foreground": ("IMAGE", {"tooltip": "Foreground image layer (can be transformed and erased)"}),
                "composition_data": ("STRING", {
                    "default": "{}",
                    "multiline": False,
                    "tooltip": "JSON transform data (auto-generated by canvas)"
                }),
                "pass_forward": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "Pass the saved composition result to downstream nodes when enabled"
                }),
            },
            "hidden": {
                "node_id": "UNIQUE_ID",
                "output_filename": ("STRING", {"default": "rc_composition.png"}),
                "auto_continue": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("image", "foreground_mask")
    FUNCTION = "composite"
    OUTPUT_NODE = True

    @classmethod
    def IS_CHANGED(cls, composition_data, pass_forward, **kwargs):
        return composition_data, pass_forward

    def composite(self, background, foreground, composition_data, pass_forward, node_id,
                 output_filename="rc_composition.png", auto_continue=False):

        # Convert images to PIL for base64 encoding
        bg_pil = tensor_to_pil(background)
        fg_pil = tensor_to_pil(foreground)

        # Use background image size as canvas size
        canvas_width, canvas_height = bg_pil.size

        # Convert to RGBA
        if bg_pil.mode != "RGBA":
            bg_pil = bg_pil.convert("RGBA")
        if fg_pil.mode != "RGBA":
            fg_pil = fg_pil.convert("RGBA")

        # Encode images as base64 for frontend
        bg_base64 = image_to_base64(bg_pil)
        fg_base64 = image_to_base64(fg_pil)

        # Prepare UI data for frontend
        ui = {
            "background_image": [bg_base64],
            "foreground_image": [fg_base64],
            "canvas_width": [canvas_width],
            "canvas_height": [canvas_height],
            "composition_data": [composition_data],
            "auto_continue": [auto_continue],
            "pass_forward": [pass_forward],
            "node_id": [node_id],
        }

        # Send initialization message to frontend
        detail = {"output": ui, "node": node_id}
        PromptServer.instance.send_sync("rc_compositor_init", detail)

        # Check if we have a saved composition
        file_exists = folder_paths.exists_annotated_filepath(output_filename)

        # Parse composition data to check if valid
        try:
            comp_data = json.loads(composition_data) if composition_data else {}
        except json.JSONDecodeError:
            comp_data = {}

        transform_data = comp_data.get("foreground") if isinstance(comp_data, dict) else None
        has_valid_data = bool(comp_data.get("saved")) if isinstance(comp_data, dict) else False

        if not pass_forward:
            raise RuntimeError(PASS_FORWARD_MESSAGE)

        if has_valid_data and file_exists:
            # Load saved composition to preserve eraser edits
            image_path = folder_paths.get_annotated_filepath(output_filename)
            pil_img = Image.open(image_path)
            pil_img = ImageOps.exif_transpose(pil_img)

            if pil_img.mode == "RGBA":
                rgb_img = Image.new("RGB", pil_img.size, (255, 255, 255))
                rgb_img.paste(pil_img, mask=pil_img.split()[3])
                alpha_channel = pil_img.split()[3]
                mask_array = np.array(alpha_channel).astype(np.float32) / 255.0
                pil_img = rgb_img
            else:
                if pil_img.mode != "RGB":
                    pil_img = pil_img.convert("RGB")
                mask_array = np.ones((pil_img.height, pil_img.width), dtype=np.float32)

            image_tensor = pil_to_tensor(pil_img)
            mask_tensor = torch.from_numpy(mask_array).unsqueeze(0)

            return {
                "ui": ui,
                "result": (image_tensor, mask_tensor)
            }

        if not transform_data:
            raise RuntimeError(PASS_FORWARD_MESSAGE)

        mask_data = comp_data.get("mask") if isinstance(comp_data, dict) else None

        composed_rgb, mask_img = compose_from_transform(bg_pil, fg_pil, transform_data, mask_data)
        if composed_rgb is None or mask_img is None:
            raise RuntimeError(PASS_FORWARD_MESSAGE)

        image_tensor = pil_to_tensor(composed_rgb)
        mask_array = np.array(mask_img).astype(np.float32) / 255.0
        mask_tensor = torch.from_numpy(mask_array).unsqueeze(0)

        return {
            "ui": ui,
            "result": (image_tensor, mask_tensor)
        }


# API routes
routes = PromptServer.instance.routes

@routes.post('/rc_compositor/save')
async def save_composition(request):
    """Save composition canvas as image"""
    try:
        data = await request.json()
        image_data = data.get("image")
        mask_data = data.get("mask")
        filename = data.get("filename", "rc_composition.png")

        # Decode base64 image
        if image_data and "base64," in image_data:
            image_data = image_data.split("base64,")[1]

        img_bytes = base64.b64decode(image_data)
        img = Image.open(BytesIO(img_bytes))

        # Save to temp folder
        filepath = folder_paths.get_annotated_filepath(filename)
        img.save(filepath, "PNG")

        return web.json_response({
            "status": "success",
            "filename": filename
        })
    except Exception as e:
        return web.json_response({
            "status": "error",
            "message": str(e)
        }, status=500)


NODE_CLASS_MAPPINGS = {
    "RC_InteractiveCompositor": RC_InteractiveCompositor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "RC_InteractiveCompositor": "RC Interactive Compositor",
}
